

### Query benchmarker

The second Python script, which runs the queries, benchmarks them and produces the graphs thanks to **matplotlib**, has a very straightforward implementation:

```python
# Get output path from command line arguments
outfile = sys.argv[1]

# Create a `master` 
m = master(make_connection("neo4j", "admin"))

# Benchmark queries
bench_query('query0', '''
    MATCH (n:patient)
    RETURN n''')

bench_query('query1', '''
    MATCH (n:patient)
    WHERE n.n = "SIVV33W0"
    RETURN n''')

bench_query('query2', '''
    MATCH (p:patient)-[r:measure]->(m:measurement)
    WITH p, m, count(m) as relcount
    WHERE p.lwalk_td < 5000 AND p.w <> 5000 AND relcount > 4
    RETURN p''')

# Create graph legends and plot to file
plt.legend(loc='upper right', shadow=True, fontsize='x-large')
plt.savefig(outfile)
```

The `bench_query` functions is implemented as follows:

```python
# Executes `q`, timing it and plotting the result
# with label `lbl`
def bench_query(lbl, q):
    xs = [] # X axis: query iteration
    ys = [] # Y axis: execution time

    for i in range(0, 50):
        xs.append(i)
        
        start_timer()
        m.exec_query(q)
        ys.append(end_timer())

    plt.plot(xs, ys, label=lbl)
```

The `start_timer` and `end_timer` functions make use of the `time.perf_counter()` Python high-precision timer in order to retrieve the execution time of every single query:

```python
# Benchmark utilities
t0 = []
def start_timer():
    global t0
    t0.append(time.perf_counter())

def end_timer():
    global t0
    val = time.perf_counter() - t0.pop()
    return val
```


### Automation script

In order to automate the whole benchmarking process, a simple **bash** script was implemented to load all datasets and execute the queries on them:

```bash
# Create `results` folder if required
mkdir -p results

# Dataset N array
VALUES=(10 100 1000 10000 100000)

# Load dataset chunk N array
CHUNKS=(1 1 1 5 10)

# Next chunk value index
ICHUNK=0

for i in "${VALUES[@]}"
do
    # Dataset path
    DS="../../dataset_lokomat/output/ds${i}.json"

    # Output graph path
    OF="./results/r${i}.png"

    # Load dataset
    python3 -O ./load_dataset.py "${DS}" "${CHUNKS[$ICHUNK]}"

    # Increment index for next chunk
    ((ICHUNK++))

    # Run queries and create plots
    python3 -O ./queries.py "${OF}"
done
```

The script, in short, simply runs the previously described Python scripts for every randomly-generated dataset, automatically passing the dataset path and a reasonable chunk value in every execution.


# Conclusion

The results of the queries are provided as histograms:

* The **X axis** represents the query iteration. Since since DBMSs have caching mechanisms, queries are repeated `50` times. Every iteration is plotted in order to measure the effect of those caching mechanisms.

* The **Y axis** represents the execution time, in milliseconds.

## Result graphs

<!-- ![la lune](lalune.jpg "Voyage to the moon") -->



## Links

The project is available on GitHub: [https://github.com/SuperV1234/db2](https://github.com/SuperV1234/db2).